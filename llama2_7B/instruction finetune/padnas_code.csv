Dataset,DataFrame,Columns,Task,Steps,ExpectedCode
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Calculate the average unit price for each item.,"Group by 'ItemCode' or 'ItemName'., Compute the average of 'UnitPrice' for each group.","avg_price_per_item = df.groupby('ItemCode').agg(AverageUnitPrice=('UnitPrice', 'mean'))"
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Find the total quantity sold for each item.,"Group by 'ItemCode' or 'ItemName'., Sum the 'Quantity' for each group.","total_quantity_per_item = df.groupby('ItemCode').agg(TotalQuantity=('Quantity', 'sum'))"
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Identify the date with the highest sales amount.,"Group by 'InvoiceDocDate'., Sum the 'TotalAmount' for each group/date., Sort in descending order and pick the top date.","sales_per_date = df.groupby('InvoiceDocDate').agg(DailySales=('TotalAmount', 'sum')).sort_values(by='DailySales', ascending=False)
highest_sales_date = sales_per_date.head(1)"
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Compute the total tax collected from sales.,Sum the 'Tax' column.,total_tax_collected = df['Tax'].sum()
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Determine the item that has been sold to the most number of unique customers.,"Group by 'ItemCode' or 'ItemName'., Count the distinct 'CustomerCode' for each group., Sort in descending order and pick the top item.","unique_customers_per_item = df.groupby('ItemCode').agg(UniqueCustomers=('CustomerCode', 'nunique')).sort_values(by='UniqueCustomers', ascending=False)
most_sold_item = unique_customers_per_item.head(1)"
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Calculate the average discount given across all sales.,Compute the mean of the 'Discount' column.,avg_discount = df['Discount'].mean()
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Find out how many items were sold on a given day.,"Filter the data by a specific 'InvoiceDocDate'., Sum the 'Quantity' for that date.","specific_date = 'YYYY-MM-DD'
items_sold_on_date = df[df['InvoiceDocDate'] == specific_date]['Quantity'].sum()"
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Identify the customer who received the highest discount in total.,"Group by 'CustomerCode' or 'CustomerName'., Sum the 'Discount' for each customer., Sort in descending order and pick the top customer.","discount_per_customer = df.groupby('CustomerCode').agg(TotalDiscount=('Discount', 'sum')).sort_values(by='TotalDiscount', ascending=False)
highest_discount_customer = discount_per_customer.head(1)"
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Calculate the total sales amount before applying any tax or discount.,"Multiply 'UnitPrice' by 'Quantity' for each row., Sum the resultant values to get the total sales amount.","df['SalesBeforeTaxDiscount'] = df['UnitPrice'] * df['Quantity']
total_sales_before = df['SalesBeforeTaxDiscount'].sum()"
Sales dataset,df,"InvoiceDocDate, CustomerCode, CustomerName, ItemCode, ItemName, UnitPrice, Quantity, Discount, Tax, TotalAmount",Find out the most sold item in terms of quantity.,"Group by 'ItemCode' or 'ItemName'., Sum the 'Quantity' for each item., Sort in descending order and pick the top item.","quantity_per_item = df.groupby('ItemCode').agg(TotalQuantity=('Quantity', 'sum')).sort_values(by='TotalQuantity', ascending=False)
top_item_by_quantity = quantity_per_item.head(1)"
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Calculate the survival rate by gender.,"Group by 'Sex'., Compute the mean of 'Survived' for each gender.","survival_by_gender = df.groupby('Sex').agg(SurvivalRate=('Survived', 'mean'))"
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Identify the passenger class with the highest survival rate.,"Group by 'Pclass'., Compute the mean of 'Survived' for each class., Sort in descending order and pick the top class.","survival_by_class = df.groupby('Pclass').agg(SurvivalRate=('Survived', 'mean')).sort_values(by='SurvivalRate', ascending=False)
highest_survival_class = survival_by_class.head(1)"
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Determine the average age of passengers who survived and those who didn't.,"Group by 'Survived'., Compute the mean of 'Age' for each group.","avg_age_by_survival = df.groupby('Survived').agg(AverageAge=('Age', 'mean'))"
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Find the total fare collected for each passenger class.,"Group by 'Pclass'., Sum the 'Fare' for each class.","fare_by_class = df.groupby('Pclass').agg(TotalFare=('Fare', 'sum'))"
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Calculate the total number of passengers embarked from each port.,"Group by 'Embarked'., Count the number of passengers for each port.",passengers_by_port = df.groupby('Embarked').size()
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Find the average fare paid by passengers based on their gender.,"Group by 'Sex'., Compute the mean of 'Fare' for each gender.","avg_fare_by_gender = df.groupby('Sex').agg(AverageFare=('Fare', 'mean'))"
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Identify the number of siblings/spouses passengers had onboard on average.,Compute the mean of the 'SibSp' column.,avg_sibsp = df['SibSp'].mean()
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Determine how many passengers traveled without any parents or children.,"Filter data for 'Parch' equal to 0., Count the number of such passengers.",passengers_without_parch = df[df['Parch'] == 0].shape[0]
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Identify the distribution of passengers across different ticket classes.,"Group by 'Pclass'., Count the number of passengers in each class.",distribution_by_class = df.groupby('Pclass').size()
Titanic Survival dataset,df,"PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked",Calculate the survival rate for passengers under the age of 18.,"Filter data for 'Age' less than 18., Compute the mean of 'Survived' for this group.",survival_rate_under_18 = df[df['Age'] < 18]['Survived'].mean()
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Calculate the prevalence of heart disease by gender.,"Group by 'sex'., Compute the mean of 'target' for each gender.","prevalence_by_gender = df.groupby('sex').agg(Prevalence=('target', 'mean'))"
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Determine the average cholesterol level for patients with and without heart disease.,"Group by 'target'., Compute the mean of 'chol' for each group.","avg_chol_by_disease = df.groupby('target').agg(AverageChol=('chol', 'mean'))"
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Find out the average age of patients who have exercise-induced angina.,"Filter data for 'exang' equal to 1., Compute the mean of 'age' for this group.",avg_age_with_angina = df[df['exang'] == 1]['age'].mean()
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Determine the maximum heart rate achieved by patients with different types of chest pain.,"Group by 'cp'., Compute the maximum of 'thalach' for each chest pain type.","max_heart_rate_by_cp = df.groupby('cp').agg(MaxHeartRate=('thalach', 'max'))"
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Calculate the prevalence of heart disease for patients with fasting blood sugar above 120 mg/dl.,"Filter data for 'fbs' equal to 1., Compute the mean of 'target' for this group.",prevalence_high_fbs = df[df['fbs'] == 1]['target'].mean()
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Identify the number of patients with a typical angina chest pain who have heart disease.,"Filter data for 'cp' equal to 1 (typical angina)., Filter the result for 'target' equal to 1 (heart disease)., Count the number of such patients.",typical_angina_disease = df[(df['cp'] == 1) & (df['target'] == 1)].shape[0]
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Determine the average resting blood pressure of females who do not have heart disease.,"Filter data for 'sex' equal to 0 (female)., Filter the result for 'target' equal to 0 (no heart disease)., Compute the mean of 'trestbps'.",avg_bp_female_no_disease = df[(df['sex'] == 0) & (df['target'] == 0)]['trestbps'].mean()
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Calculate the prevalence of heart disease for patients with a reversible defect in thalassemia.,"Filter data for 'thal' equal to 7 (reversible defect)., Compute the mean of 'target' for this group.",prevalence_reversible_defect = df[df['thal'] == 7]['target'].mean()
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Identify the average ST depression ('oldpeak') induced by exercise for males with heart disease.,"Filter data for 'sex' equal to 1 (male)., Filter the result for 'target' equal to 1 (heart disease)., Compute the mean of 'oldpeak'.",avg_oldpeak_male_disease = df[(df['sex'] == 1) & (df['target'] == 1)]['oldpeak'].mean()
Heart Disease dataset,df,"age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal, target",Find out how many patients have zero major vessels colored by fluoroscopy and still have heart disease.,"Filter data for 'ca' equal to 0., Filter the result for 'target' equal to 1 (heart disease)., Count the number of such patients.",zero_vessels_disease = df[(df['ca'] == 0) & (df['target'] == 1)].shape[0]
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Determine the average age of individuals for each income bracket.,"Group by 'income'., Compute the mean of 'age' for each income group.","avg_age_by_income = df.groupby('income').agg(AverageAge=('age', 'mean'))"
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Calculate the proportion of individuals with a bachelor's degree who earn more than $50K annually.,"Filter data for 'education' equal to 'Bachelors'., Compute the mean of 'income' being '>50K' for this group.",bachelors_high_income_ratio = (df[df['education'] == 'Bachelors']['income'] == '>50K').mean()
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Identify the most common occupation among females who earn more than $50K annually.,"Filter data for 'sex' equal to 'Female' and 'income' equal to '>50K'., Identify the mode of 'occupation' for this group.",common_occupation = df[(df['sex'] == 'Female') & (df['income'] == '>50K')]['occupation'].mode()[0]
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Find out the average hours worked per week for individuals who are 'Never-married' and earn more than $50K annually.,"Filter data for 'marital-status' equal to 'Never-married' and 'income' equal to '>50K'., Compute the mean of 'hours-per-week' for this group.",avg_hours_never_married = df[(df['marital-status'] == 'Never-married') & (df['income'] == '>50K')]['hours-per-week'].mean()
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Determine the proportion of individuals who work in the private sector and have capital gains greater than 5000.,"Filter data for 'workclass' equal to 'Private'., Compute the proportion of these individuals with 'capital-gain' greater than 5000.",private_sector_high_gain_ratio = (df[df['workclass'] == 'Private']['capital-gain'] > 5000).mean()
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Determine the total number of unique occupations in the dataset.,"Extract unique values from the 'occupation' column., Count the number of unique occupations.",num_unique_occupations = df['occupation'].nunique()
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Calculate the median age of individuals whose native country is not the 'United-States'.,"Filter data where 'native-country' is not equal to 'United-States'., Compute the median age for this filtered group.",median_age_foreign = df[df['native-country'] != 'United-States']['age'].median()
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Determine the percentage of individuals who are 'Self-emp' (self-employed) and have an income exceeding $50K.,"Filter data for 'workclass' containing 'Self-emp' and 'income' equal to '>50K'., Compute the ratio of this filtered group to the entire dataset and multiply by 100 to get the percentage.",self_emp_high_income_percentage = (len(df[(df['workclass'].str.contains('Self-emp')) & (df['income'] == '>50K')]) / len(df)) * 100
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Identify the average capital loss of individuals who work more than 40 hours per week.,"Filter data for 'hours-per-week' greater than 40., Compute the mean of 'capital-loss' for this group.",avg_capital_loss_over_40hrs = df[df['hours-per-week'] > 40]['capital-loss'].mean()
Adult Income dataset,df,"age, workclass, education, education-num, marital-status, occupation, relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income",Find out the most common education level among individuals whose income exceeds $50K.,"Filter data for 'income' equal to '>50K'., Identify the mode of 'education' for this group.",common_education_high_income = df[df['income'] == '>50K']['education'].mode()[0]
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Calculate the average alcohol content for each wine class.,"Group by 'Class'., Compute the mean of 'Alcohol' for each class.","avg_alcohol_by_class = df.groupby('Class').agg(AverageAlcohol=('Alcohol', 'mean'))"
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Determine the wine class with the highest average magnesium content.,"Group by 'Class'., Compute the mean of 'Magnesium' for each class., Identify the class with the highest mean magnesium.","class_with_highest_magnesium = df.groupby('Class').agg(AverageMagnesium=('Magnesium', 'mean')).idxmax().iloc[0]"
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Calculate the correlation between 'Total phenols' and 'Flavanoids'.,Compute the correlation between 'Total phenols' and 'Flavanoids'.,correlation = df['Total phenols'].corr(df['Flavanoids'])
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Find out the average color intensity of wines with hue greater than 1.0.,"Filter data where 'Hue' is greater than 1.0., Compute the mean of 'Color intensity' for this filtered data.",avg_color_intensity = df[df['Hue'] > 1.0]['Color intensity'].mean()
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Determine the wine class with the lowest average 'OD280/OD315 of diluted wines'.,"Group by 'Class'., Compute the mean of 'OD280/OD315 of diluted wines' for each class., Identify the class with the lowest mean value for this attribute.","class_with_lowest_OD280_OD315 = df.groupby('Class').agg(AverageOD280_OD315=('OD280/OD315 of diluted wines', 'mean')).idxmin().iloc[0]"
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Determine the average 'Alcalinity of ash' for wines with an 'Alcohol' content above 12.5.,"Filter data where 'Alcohol' is greater than 12.5., Compute the mean of 'Alcalinity of ash' for the filtered data.",avg_alcalinity_high_alcohol = df[df['Alcohol'] > 12.5]['Alcalinity of ash'].mean()
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Find the class of wine that has the highest average 'Proline' content.,"Group by 'Class'., Compute the mean of 'Proline' for each class., Identify the class with the highest mean 'Proline'.","class_with_highest_proline = df.groupby('Class').agg(AverageProline=('Proline', 'mean')).idxmax().iloc[0]"
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Calculate the correlation between 'Color intensity' and 'Hue'.,Compute the correlation between 'Color intensity' and 'Hue'.,color_hue_correlation = df['Color intensity'].corr(df['Hue'])
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Identify the wine class with the lowest average 'Nonflavanoid phenols'.,"Group by 'Class'., Compute the mean of 'Nonflavanoid phenols' for each class., Identify the class with the lowest mean 'Nonflavanoid phenols'.","class_with_lowest_nonflavanoids = df.groupby('Class').agg(AverageNonflavanoids=('Nonflavanoid phenols', 'mean')).idxmin().iloc[0]"
Wine dataset,df,"Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, Proline, Class",Find out the median 'Malic acid' content for wines with 'Flavanoids' below 1.5.,"Filter data where 'Flavanoids' is less than 1.5., Compute the median of 'Malic acid' for this filtered group.",median_malic_low_flavanoids = df[df['Flavanoids'] < 1.5]['Malic acid'].median()
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Determine the average 'Mean radius' for benign tumors.,"Filter data for benign tumors (where 'Target' is 0)., Compute the mean of 'Mean radius' for benign tumors.",avg_radius_benign = df[df['Target'] == 0]['Mean radius'].mean()
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Find out the median 'Mean texture' for malignant tumors.,"Filter data for malignant tumors (where 'Target' is 1)., Compute the median of 'Mean texture' for malignant tumors.",median_texture_malignant = df[df['Target'] == 1]['Mean texture'].median()
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Calculate the correlation between 'Mean perimeter' and 'Mean area'.,Compute the correlation between 'Mean perimeter' and 'Mean area'.,perimeter_area_correlation = df['Mean perimeter'].corr(df['Mean area'])
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Determine the average 'Mean smoothness' for all tumors.,Compute the mean of 'Mean smoothness' for the entire dataset.,avg_smoothness = df['Mean smoothness'].mean()
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Find the maximum 'Mean concavity' observed for benign tumors.,"Filter data for benign tumors (where 'Target' is 0)., Identify the maximum value of 'Mean concavity' for benign tumors.",max_concavity_benign = df[df['Target'] == 0]['Mean concavity'].max()
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Determine the minimum 'Mean area' for malignant tumors.,"Filter data for malignant tumors (where 'Target' is 1)., Compute the minimum of 'Mean area' for malignant tumors.",min_area_malignant = df[df['Target'] == 1]['Mean area'].min()
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Calculate the correlation between 'Mean compactness' and 'Mean concave points'.,Compute the correlation between 'Mean compactness' and 'Mean concave points'.,compactness_concave_points_correlation = df['Mean compactness'].corr(df['Mean concave points'])
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Identify the average 'Mean symmetry' for benign tumors.,"Filter data for benign tumors (where 'Target' is 0)., Compute the mean of 'Mean symmetry' for benign tumors.",avg_symmetry_benign = df[df['Target'] == 0]['Mean symmetry'].mean()
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Find out how many tumors have a 'Mean fractal dimension' above 0.07.,"Filter data where 'Mean fractal dimension' is greater than 0.07., Count the number of such records.",count_high_fractal_dimension = df[df['Mean fractal dimension'] > 0.07].shape[0]
Breast Cancer dataset,df,"Mean radius, Mean texture, Mean perimeter, Mean area, Mean smoothness, Mean compactness, Mean concavity, Mean concave points, Mean symmetry, Mean fractal dimension, Target",Determine the median 'Mean smoothness' for all tumors.,Compute the median of 'Mean smoothness' for the entire dataset.,median_smoothness = df['Mean smoothness'].median()
